{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'str'>\n",
      "dict_keys(['tinywebm', 'webm', 'tinygif', 'nanogifpreview', 'loopedmp4', 'gifpreview', 'mediumgif', 'nanogif', 'tinymp4', 'tinygifpreview', 'gif', 'nanomp4', 'mp4', 'nanowebm'])\n",
      "dict_keys(['nanogif', 'tinygifpreview', 'gifpreview', 'mp4', 'mediumgif', 'nanowebm', 'tinymp4', 'nanogifpreview', 'loopedmp4', 'tinywebm', 'tinygif', 'nanomp4', 'gif', 'webm'])\n",
      "dict_keys(['tinygifpreview', 'nanowebm', 'loopedmp4', 'nanogif', 'tinygif', 'nanogifpreview', 'tinywebm', 'tinymp4', 'nanomp4', 'mp4', 'gifpreview', 'gif', 'mediumgif', 'webm'])\n",
      "dict_keys(['webm', 'tinymp4', 'nanogif', 'nanogifpreview', 'loopedmp4', 'gifpreview', 'mp4', 'nanowebm', 'mediumgif', 'tinygif', 'tinywebm', 'tinygifpreview', 'nanomp4', 'gif'])\n",
      "dict_keys(['nanomp4', 'nanogifpreview', 'nanogif', 'loopedmp4', 'webm', 'tinymp4', 'tinygif', 'gif', 'mediumgif', 'nanowebm', 'tinygifpreview', 'gifpreview', 'mp4', 'tinywebm'])\n",
      "dict_keys(['gif', 'nanogif', 'tinymp4', 'tinygifpreview', 'loopedmp4', 'nanomp4', 'nanogifpreview', 'nanowebm', 'mp4', 'gifpreview', 'webm', 'mediumgif', 'tinygif', 'tinywebm'])\n",
      "dict_keys(['tinygif', 'webm', 'nanogifpreview', 'loopedmp4', 'gifpreview', 'tinymp4', 'tinygifpreview', 'nanowebm', 'tinywebm', 'nanomp4', 'nanogif', 'gif', 'mp4', 'mediumgif'])\n",
      "dict_keys(['tinymp4', 'tinygif', 'nanomp4', 'tinygifpreview', 'mp4', 'tinywebm', 'nanowebm', 'mediumgif', 'nanogif', 'webm', 'nanogifpreview', 'loopedmp4', 'gif', 'gifpreview'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'str'>\n",
      "dict_keys(['gifpreview', 'tinygif', 'nanogif', 'nanowebm', 'tinymp4', 'mp4', 'nanomp4', 'mediumgif', 'loopedmp4', 'tinygifpreview', 'nanogifpreview', 'gif', 'webm', 'tinywebm'])\n",
      "dict_keys(['tinygifpreview', 'nanomp4', 'tinywebm', 'webm', 'loopedmp4', 'nanogif', 'nanowebm', 'nanogifpreview', 'gifpreview', 'tinymp4', 'mp4', 'gif', 'tinygif', 'mediumgif'])\n",
      "dict_keys(['nanomp4', 'tinygifpreview', 'nanogif', 'nanowebm', 'gif', 'webm', 'gifpreview', 'loopedmp4', 'tinygif', 'nanogifpreview', 'tinymp4', 'mediumgif', 'tinywebm', 'mp4'])\n",
      "dict_keys(['gifpreview', 'loopedmp4', 'tinygif', 'mediumgif', 'tinymp4', 'tinywebm', 'webm', 'nanomp4', 'nanogif', 'nanogifpreview', 'tinygifpreview', 'nanowebm', 'mp4', 'gif'])\n",
      "dict_keys(['nanogif', 'nanowebm', 'webm', 'mp4', 'tinygifpreview', 'tinywebm', 'gif', 'tinymp4', 'nanogifpreview', 'gifpreview', 'tinygif', 'mediumgif', 'nanomp4', 'loopedmp4'])\n",
      "dict_keys(['webm', 'nanowebm', 'gifpreview', 'tinygifpreview', 'nanomp4', 'nanogif', 'tinywebm', 'nanogifpreview', 'loopedmp4', 'tinygif', 'gif', 'mp4', 'mediumgif', 'tinymp4'])\n",
      "dict_keys(['tinygif', 'mediumgif', 'gif', 'gifpreview', 'webm', 'nanogif', 'nanogifpreview', 'nanowebm', 'nanomp4', 'mp4', 'tinymp4', 'loopedmp4', 'tinygifpreview', 'tinywebm'])\n",
      "dict_keys(['mediumgif', 'tinymp4', 'gif', 'nanowebm', 'tinygifpreview', 'webm', 'loopedmp4', 'gifpreview', 'nanomp4', 'tinywebm', 'nanogifpreview', 'tinygif', 'mp4', 'nanogif'])\n"
     ]
    }
   ],
   "source": [
    "import requests, json, secret\n",
    "\n",
    "apikey = secret.tenor_api_key\n",
    "client_key = \"pinkbot_discord\"\n",
    "search = \"punch\"\n",
    "limit = 8\n",
    "r = requests.get(f\"https://tenor.googleapis.com/v2/search?q='{search} anime'&key={apikey}&client_key={client_key}&limit={limit}\")\n",
    "\n",
    "if r.status_code == 200:\n",
    "    # load the GIFs using the urls for the smaller GIF sizes\n",
    "    top_8gifs = json.loads(r.content)\n",
    "    for i in top_8gifs:\n",
    "        print(type(i), type(top_8gifs[i]))\n",
    "else:\n",
    "    top_8gifs = None\n",
    "\n",
    "for i in top_8gifs['results']:\n",
    "    print(i['media_formats'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "import requests, bs4\n",
    "\n",
    "username = \"hannahowo\"\n",
    "page = 2\n",
    "\n",
    "homepage = \"https://coomer.su\"\n",
    "\n",
    "pretext = \"/onlyfans/user/f1nn5ter/post\"\n",
    "codes = []\n",
    "\n",
    "r = requests.get(f\"https://coomer.su/onlyfans/user/{username}?o={(page-1)*50}\", allow_redirects=False)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    soup = bs4.BeautifulSoup(r.text, \"lxml\")\n",
    "    links = [element[\"href\"].lstrip(pretext) for element in soup.find_all(\"a\") if element[\"href\"].startswith(pretext)]\n",
    "    print(len(links), links)\n",
    "else:\n",
    "    print(f\"User {username} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sarka\\Home\\Programs\\discord_py\\pinkbot\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sarka/Home/Programs/discord_py/pinkbot/test.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m soup \u001b[39m=\u001b[39m bs4\u001b[39m.\u001b[39mBeautifulSoup(r\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sarka/Home/Programs/discord_py/pinkbot/test.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m codes \u001b[39m=\u001b[39m [element[\u001b[39m\"\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlstrip(pretext) \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m element[\u001b[39m\"\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstartswith(pretext)]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sarka/Home/Programs/discord_py/pinkbot/test.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mhomepage\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpretext\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcodes[\u001b[39m30\u001b[39;49m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sarka/Home/Programs/discord_py/pinkbot/test.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m soup \u001b[39m=\u001b[39m bs4\u001b[39m.\u001b[39mBeautifulSoup(r\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sarka/Home/Programs/discord_py/pinkbot/test.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m images \u001b[39m=\u001b[39m [element[\u001b[39m\"\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfileThumb\u001b[39m\u001b[39m\"\u001b[39m})]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests, bs4\n",
    "\n",
    "username = \"f1nn5ter\"\n",
    "page = 5\n",
    "\n",
    "homepage = \"https://coomer.su\"\n",
    "\n",
    "pretext = f\"/onlyfans/user/{username}/post\"\n",
    "\n",
    "r = requests.get(f\"https://coomer.su/onlyfans/user/{username}?o={(page-1)*50}\", allow_redirects=False)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    soup = bs4.BeautifulSoup(r.text, \"lxml\")\n",
    "    codes = [element[\"href\"].lstrip(pretext) for element in soup.find_all(\"a\") if element[\"href\"].startswith(pretext)]\n",
    "    r = requests.get(f\"{homepage}{pretext}/{codes[30]}\")\n",
    "    soup = bs4.BeautifulSoup(r.text, \"lxml\")\n",
    "    images = [element[\"href\"] for element in soup.find_all(\"a\", {\"class\": \"fileThumb\"})]\n",
    "    print(f\"Images ({len(images)}): {images}\")\n",
    "    videos = [element.find(\"source\")[\"src\"] for element in soup.find_all(\"video\", {\"class\": \"post__video\"})]\n",
    "    print(f\"Videos ({len(videos)}): {videos}\")\n",
    "\n",
    "else:\n",
    "    print(f\"User {username} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import requests, bs4, typing\n",
    "\n",
    "def generate_code(username: str, start: int = 0) -> typing.Generator[str, None, None]:\n",
    "    # defining some required values\n",
    "    posts_per_page = 50\n",
    "    homepage = \"https://coomer.su\"\n",
    "    userpage = \"onlyfans/user\"\n",
    "    # getting current page data\n",
    "    start -= 1\n",
    "    current_page = (start // posts_per_page) * posts_per_page\n",
    "    start %= 50\n",
    "    codes = [0]             # so than length is not zero\n",
    "    while len(codes) > 0:\n",
    "        pageurl = f\"{homepage}/{userpage}/{username}?o={current_page}\"\n",
    "        r = requests.get(pageurl, allow_redirects=False)\n",
    "        soup = bs4.BeautifulSoup(r.text, \"html.parser\")\n",
    "        # getting codes\n",
    "        prehref = f\"/{userpage}/{username}/post\"\n",
    "        codes = [element[\"href\"].lstrip(prehref) for element in soup.find_all(\"a\") if element[\"href\"].startswith(prehref)]\n",
    "        for i in range(start, len(codes)):\n",
    "            yield codes[i]\n",
    "        start = 0\n",
    "        current_page += posts_per_page\n",
    "\n",
    "generated = generate_code(\"nikumikyo\", 850)\n",
    "print(all(generated))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discord_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
